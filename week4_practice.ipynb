{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week4_practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudht/NLP/blob/master/week4_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgwtakNcxyw2",
        "colab_type": "code",
        "outputId": "afe2db15-0ea8-4a26-a221-fad683a30b6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr6G6Pfuxzrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "dir = '/gdrive/My Drive/colab/week4'\n",
        "\n",
        "label_dict = {'spam':0, 'ham':1}\n",
        "# 파일 읽기\n",
        "X_data = []\n",
        "y_data = []\n",
        "with open(dir + '/SMSSpamCollection','r',encoding='utf8') as infile:\n",
        "  for line in infile:\n",
        "    line = line.strip().split('\\t')\n",
        "    X_data.append(line[1])\n",
        "    y_data.append(label_dict[line[0]])       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDHM6PINCLTt",
        "colab_type": "code",
        "outputId": "b4211453-de0c-4bed-8c78-26a1686a40cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "\n",
        "# 아래의 함수를 사용하여 전체 데이터 중 100개의 데이터만 가지고 사전 생성 및 인덱스 매핑 코드를 작성하시오.\n",
        "\n",
        "\n",
        "\n",
        "# tokenizer.fit_on_texts(data)\n",
        "# args\n",
        "#    data : 문자열 element를 가지고 있는 list\n",
        "# return\n",
        "#    X\n",
        "# 입력받은 데이터로부터 단어장 생성\n",
        "#\n",
        "\n",
        "\n",
        "\n",
        "# tokenizer.texts_to_sequence(data)\n",
        "# args\n",
        "#    data : 문자열 element를 가지고 있는 list\n",
        "# return : \n",
        "#    int형 list\n",
        "# ex)\n",
        "# result = tokenizer.texts_to_sequences([i love car])\n",
        "# result : [12, 65, 98 , 78]\n",
        "# 입력 받은 문자열 리스트를 단어장에 매핑하여 숫자열 리스트를 반환\n",
        "\n",
        "print(X_data[0])\n",
        "\n",
        "########################################################\n",
        "# for i in range(100):\n",
        "#   tokenizer.fit_on_texts(X_data[i])\n",
        "  \n",
        "X_data = X_data[:100]\n",
        "tokenizer.fit_on_texts(X_data)\n",
        "X_data = tokenizer.texts_to_sequences(X_data)\n",
        "\n",
        "########################################################\n",
        "\n",
        "print(X_data[0])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "[38, 93, 239, 240, 241, 242, 53, 11, 243, 72, 94, 244, 245, 126, 246, 247, 73, 74, 248, 127]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8bTL9TEhJD0",
        "colab_type": "code",
        "outputId": "1f818fb1-7076-4735-8ec0-4f412540917c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "import operator\n",
        "\n",
        "\n",
        "\n",
        "svm = SVC(kernel='linear', C=1e10)\n",
        "\n",
        "\n",
        "# 2. 입력하는 모든 데이터의 길이를 60의 고정된 길이로 변환하는 코드 작성\n",
        "########################################################\n",
        "# for i in X_data:\n",
        "#   tmp = [0 for j in range(60)]\n",
        "#   j = 0\n",
        "#   while j < len(i):\n",
        "#     tmp[j] = i[j]\n",
        "#     j = j+1\n",
        "#   i = tmp\n",
        "  \n",
        "max_length = 60\n",
        "# e는 I love you\n",
        "# [0] * 은 패딩 공간\n",
        "X_data = [e + [0]*(max_length-len(e)) for e in X_data]\n",
        "########################################################\n",
        "\n",
        "\n",
        "\n",
        "# 3. 전체 데이터를 9:1의 비율로 나누어 학습 및 평가 데이터로 나누는 코드 작성\n",
        "########################################################\n",
        "a = len(X_data)*0.9\n",
        "train_x = X_data[:int(a)]\n",
        "train_y = y_data[:int(a)]\n",
        "test_x = X_data[int(a):len(X_data)]\n",
        "test_y = y_data[int(a):len(X_data)]\n",
        "########################################################\n",
        "\n",
        "svm.fit(train_x, train_y)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10000000000.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
              "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
              "    shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3GK9WDahO0R",
        "colab_type": "code",
        "outputId": "498a1f92-15ca-4c70-f536-849e325f11ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# 4. 정답 값과 예측 값을 입력 받아 성능을 측정하는 모듈 작성\n",
        "# def accuracy_score(answer, predict):\n",
        "# args\n",
        "#    answer : int 형 list\n",
        "#    predict : int 형 list\n",
        "# return\n",
        "#     accuracy score : 맞힌 데이터 수 / 전체 데이터 수\n",
        "\n",
        "########################################################\n",
        "def accuracy_score(answer, predict):\n",
        "  count = 0\n",
        "  for i in range(len(answer)):\n",
        "    if answer[i] == predict[i]:\n",
        "      count = count + 1\n",
        "      \n",
        "  return count / len(answer)\n",
        "########################################################\n",
        "\n",
        "pred_y = svm.predict(test_x)\n",
        "print('Accuracy: ',accuracy_score(test_y, pred_y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 0, 1, 0, 1, 1, 1, 1]\n",
            "[0 0 1 0 1 0 1 1 1 1]\n",
            "Accuracy:  0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkS96VCeiwx4",
        "colab_type": "code",
        "outputId": "0e914e77-e073-4411-8b88-05df564a7891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        }
      },
      "source": [
        "label_dict = {0:'spam', 1:'ham'}\n",
        "\n",
        "for idx, sequence in enumerate(test_x):\n",
        "  print('\\n##################################################################')\n",
        "  print(\"Input Sequence : \", tokenizer.sequences_to_texts([sequence])[0])\n",
        "  print(\"Answer Label : \", label_dict[test_y[idx]])\n",
        "  print(\"Predict Label : \", label_dict[pred_y[idx]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "##################################################################\n",
            "Input Sequence :  yeah do don‘t stand to close tho you‘ll catch something\n",
            "Answer Label :  ham\n",
            "Predict Label :  spam\n",
            "\n",
            "##################################################################\n",
            "Input Sequence :  sorry to be a pain is it ok if we meet another night i spent late afternoon in casualty and that means i haven't done any of y stuff42moro and that includes all my time sheets and that sorry\n",
            "Answer Label :  ham\n",
            "Predict Label :  spam\n",
            "\n",
            "##################################################################\n",
            "Input Sequence :  smile in pleasure smile in pain smile when trouble pours like rain smile when sum1 hurts u smile becoz someone still loves to see u smiling\n",
            "Answer Label :  ham\n",
            "Predict Label :  ham\n",
            "\n",
            "##################################################################\n",
            "Input Sequence :  please call our customer service representative on 0800 169 6031 between 10am 9pm as you have won a guaranteed ￡1000 cash or ￡5000 prize\n",
            "Answer Label :  spam\n",
            "Predict Label :  spam\n",
            "\n",
            "##################################################################\n",
            "Input Sequence :  havent planning to buy later i check already lido only got 530 show in e afternoon u finish work already\n",
            "Answer Label :  ham\n",
            "Predict Label :  ham\n",
            "\n",
            "##################################################################\n",
            "Input Sequence :  your free ringtone is waiting to be collected simply text the password mix to 85069 to verify get usher and britney fml po box 5249 mk17 92h 450ppw 16\n",
            "Answer Label :  spam\n",
            "Predict Label :  spam\n",
            "\n",
            "##################################################################\n",
            "Input Sequence :  watching telugu movie wat abt u\n",
            "Answer Label :  ham\n",
            "Predict Label :  ham\n",
            "\n",
            "##################################################################\n",
            "Input Sequence :  i see when we finish we have loads of loans to pay\n",
            "Answer Label :  ham\n",
            "Predict Label :  ham\n",
            "\n",
            "##################################################################\n",
            "Input Sequence :  hi wk been ok on hols now yes on for a bit of a run forgot that i have hairdressers appointment at four so need to get home n shower beforehand does that cause prob for u\n",
            "Answer Label :  ham\n",
            "Predict Label :  ham\n",
            "\n",
            "##################################################################\n",
            "Input Sequence :  i see a cup of coffee animation\n",
            "Answer Label :  ham\n",
            "Predict Label :  ham\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}